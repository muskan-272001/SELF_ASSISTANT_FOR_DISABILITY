{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39e53401",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sign Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a22a0c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SignLanguageDetection():\n",
    "    WORKSPACE_PATH = 'Tensorflow/workspace'\n",
    "    SCRIPTS_PATH = 'Tensorflow/scripts'\n",
    "    APIMODEL_PATH = 'Tensorflow/models'\n",
    "    ANNOTATION_PATH = WORKSPACE_PATH + '/annotations'\n",
    "    IMAGE_PATH = WORKSPACE_PATH + '/images'\n",
    "    MODEL_PATH = WORKSPACE_PATH + '/models'\n",
    "    PRETRAINED_MODEL_PATH = WORKSPACE_PATH + '/pre-trained-models'\n",
    "    CONFIG_PATH = MODEL_PATH + '/my_ssd_mobnet/pipeline.config'\n",
    "    CHECKPOINT_PATH = MODEL_PATH + '/my_ssd_mobnet/'\n",
    "\n",
    "    labels = [\n",
    "        {'name': 'hello', 'id': 1},\n",
    "        {'name': 'thanks', 'id': 2},\n",
    "        {'name': 'yes', 'id': 3},\n",
    "        {'name': 'no', 'id': 4},\n",
    "        {'name': 'i love you', 'id': 5},\n",
    "        {'name': 'repeat', 'id': 6},\n",
    "        {'name': 'help', 'id': 7},\n",
    "        {'name': 'house', 'id': 8},\n",
    "        {'name': 'what', 'id': 9},\n",
    "        {'name': 'family', 'id': 10},\n",
    "        {'name': 'sorry', 'id': 11}\n",
    "    ]\n",
    "\n",
    "    with open(ANNOTATION_PATH + '\\label_map.pbtxt', 'w') as f:\n",
    "        for label in labels:\n",
    "            f.write('item { \\n')\n",
    "            f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "            f.write('\\tid:{}\\n'.format(label['id']))\n",
    "            f.write('}\\n')\n",
    "\n",
    "    CUSTOM_MODEL_NAME = 'my_ssd_mobnet'\n",
    "\n",
    "    import tensorflow as tf\n",
    "    from object_detection.utils import config_util\n",
    "    from object_detection.protos import pipeline_pb2\n",
    "    from google.protobuf import text_format\n",
    "\n",
    "    CONFIG_PATH = MODEL_PATH + '/' + CUSTOM_MODEL_NAME + '/pipeline.config'\n",
    "\n",
    "    CONFIG_PATH\n",
    "\n",
    "    config = config_util.get_configs_from_pipeline_file(CONFIG_PATH)\n",
    "\n",
    "    config\n",
    "\n",
    "    pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "    with tf.io.gfile.GFile(CONFIG_PATH, \"r\") as f:\n",
    "        proto_str = f.read()\n",
    "        text_format.Merge(proto_str, pipeline_config)\n",
    "\n",
    "    pipeline_config.model.ssd.num_classes = 11\n",
    "    pipeline_config.train_config.batch_size = 4\n",
    "    pipeline_config.train_config.fine_tune_checkpoint = PRETRAINED_MODEL_PATH + '/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0'\n",
    "    pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "    pipeline_config.train_input_reader.label_map_path = ANNOTATION_PATH + '/label_map.pbtxt'\n",
    "    pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [ANNOTATION_PATH + '/train.record']\n",
    "    pipeline_config.eval_input_reader[0].label_map_path = ANNOTATION_PATH + '/label_map.pbtxt'\n",
    "    pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [ANNOTATION_PATH + '/test.record']\n",
    "\n",
    "    config_text = text_format.MessageToString(pipeline_config)\n",
    "    with tf.io.gfile.GFile(CONFIG_PATH, \"wb\") as f:\n",
    "        f.write(config_text)\n",
    "\n",
    "    import os  # **\n",
    "    from object_detection.utils import label_map_util\n",
    "    from object_detection.utils import visualization_utils as viz_utils\n",
    "    from object_detection.builders import model_builder\n",
    "\n",
    "    # Load pipeline config and build a detection model#**\n",
    "    configs = config_util.get_configs_from_pipeline_file(CONFIG_PATH)\n",
    "    detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "    # Restore checkpoint\n",
    "    ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "    ckpt.restore(os.path.join(CHECKPOINT_PATH, 'ckpt-11')).expect_partial()\n",
    "\n",
    "    @tf.function\n",
    "    def detect_fn(image):\n",
    "        image, shapes = detection_model.preprocess(image)\n",
    "        prediction_dict = detection_model.predict(image, shapes)\n",
    "        detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "        return detections\n",
    "\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "\n",
    "    category_index = label_map_util.create_category_index_from_labelmap(ANNOTATION_PATH + '/label_map.pbtxt')\n",
    "\n",
    "    # Setup capture\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        image_np = np.array(frame)\n",
    "\n",
    "        input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "        detections = detect_fn(input_tensor)\n",
    "\n",
    "        num_detections = int(detections.pop('num_detections'))\n",
    "        detections = {key: value[0, :num_detections].numpy()\n",
    "                      for key, value in detections.items()}\n",
    "        detections['num_detections'] = num_detections\n",
    "\n",
    "        # detection_classes should be ints.\n",
    "        detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "        label_id_offset = 1\n",
    "        image_np_with_detections = image_np.copy()\n",
    "\n",
    "        viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_detections,\n",
    "            detections['detection_boxes'],\n",
    "            detections['detection_classes'] + label_id_offset,\n",
    "            detections['detection_scores'],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=5,\n",
    "            min_score_thresh=.5,\n",
    "            agnostic_mode=False)\n",
    "\n",
    "        cv2.imshow('Sign Language Detection', cv2.resize(image_np_with_detections, (800, 600)))\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            cap.release()\n",
    "            break\n",
    "\n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "# SignLanguageDetection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a841ad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################Voicemail#################3\n",
    "import smtplib\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "# from email.message import EmailMessage\n",
    "import easyimap as e\n",
    "\n",
    "unm = 'sahuamisha@kccemsr.edu.in'\n",
    "pwd = 'Kccemsr@12345'\n",
    "\n",
    "r = sr.Recognizer()\n",
    "engine = pyttsx3.init()\n",
    "voices = engine.getProperty('voices')\n",
    "engine.setProperty('voices', voices[1].id)\n",
    "engine.setProperty('rate', 150)\n",
    "\n",
    "\n",
    "def speak(str):\n",
    "    print(str)\n",
    "    engine.say(str)\n",
    "    engine.runAndWait()\n",
    "\n",
    "\n",
    "def listen():\n",
    "    with sr.Microphone() as source:\n",
    "        r.adjust_for_ambient_noise(source)\n",
    "        str = \"Speak Now:\"\n",
    "        speak(str)\n",
    "        audio = r.listen(source)\n",
    "        try:\n",
    "            text = r.recognize_google(audio)\n",
    "            return text\n",
    "        except:\n",
    "            str = \"Sorry could not recognize what you said\"\n",
    "            speak(str)\n",
    "\n",
    "\n",
    "def sendmail():\n",
    "    rec = 'muskankpandey100@gmail.com'\n",
    "\n",
    "    str = \"Please speak the body of your email\"\n",
    "    speak(str)\n",
    "    msg = listen()\n",
    "\n",
    "    str = \"You have spoken the message\"\n",
    "    speak(str)\n",
    "    speak(msg)\n",
    "\n",
    "    server = smtplib.SMTP_SSL(\"smtp.gmail.com\", 465)\n",
    "    server.login(unm, pwd)\n",
    "    server.sendmail(unm, rec, msg)\n",
    "    server.quit()\n",
    "\n",
    "    str = \"The mail has been sent\"\n",
    "    speak(str)\n",
    "\n",
    "\n",
    "def readmail():\n",
    "    server = e.connect(\"imap.gmail.com\", unm, pwd)\n",
    "    server.listids()\n",
    "\n",
    "    str = \"Please say the Serial Number of the email you wana read starting from latest\"\n",
    "    speak(str)\n",
    "\n",
    "    a = listen()\n",
    "    if (a == \"Tu\"):\n",
    "        a = \"2\"\n",
    "\n",
    "    b = int(a) - 1\n",
    "    email = server.mail(server.listids()[b])\n",
    "\n",
    "    str = \"The email is from: \"\n",
    "    speak(str)\n",
    "    speak(email.from_addr)\n",
    "    str = \"The subject of the email is: \"\n",
    "    speak(str)\n",
    "    speak(email.title)\n",
    "    str = \"The body of email is:\"\n",
    "    speak(str)\n",
    "    # speak(str)\n",
    "    speak(email.body)\n",
    "\n",
    "\n",
    "def voicemail():\n",
    "    str = \"Welcome to voice controlled email service\"\n",
    "    speak(str)\n",
    "\n",
    "    while (True):\n",
    "        str = \"Speak SEND to Send email   Speak READ to Read Inbox    Speak EXIT to exit\"\n",
    "        speak(str)\n",
    "\n",
    "        ch = listen()\n",
    "\n",
    "        if (ch == 'send'):\n",
    "            str = \"You have choosen to send an email\"\n",
    "            speak(str)\n",
    "            sendmail()\n",
    "\n",
    "        elif (ch == \"read\"):\n",
    "            str = \"You have choosen to read the email\"\n",
    "            speak(str)\n",
    "            readmail()\n",
    "\n",
    "        elif (ch == \"exit\"):\n",
    "            str = \"You have choosen to exit,Bye bye\"\n",
    "            speak(str)\n",
    "            # exit(True)\n",
    "            break;\n",
    "\n",
    "        else:\n",
    "            str = \"Invalid choice.\"\n",
    "            speak(str)\n",
    "\n",
    "\n",
    "# voicemail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5cdb239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to voice controlled email service\n",
      "Speak SEND to Send email   Speak READ to Read Inbox    Speak EXIT to exit\n",
      "Speak Now:\n",
      "Sorry could not recognize what you said\n",
      "Invalid choice.\n",
      "Speak SEND to Send email   Speak READ to Read Inbox    Speak EXIT to exit\n",
      "Speak Now:\n",
      "You have choosen to send an email\n",
      "Please speak the body of your email\n",
      "Speak Now:\n",
      "You have spoken the message\n",
      "good afternoon\n",
      "The mail has been sent\n",
      "Speak SEND to Send email   Speak READ to Read Inbox    Speak EXIT to exit\n",
      "Speak Now:\n",
      "Sorry could not recognize what you said\n",
      "Invalid choice.\n",
      "Speak SEND to Send email   Speak READ to Read Inbox    Speak EXIT to exit\n",
      "Speak Now:\n",
      "You have choosen to read the email\n",
      "Please say the Serial Number of the email you wana read starting from latest\n",
      "Speak Now:\n",
      "The email is from: \n",
      "BHARATI SINGH <singhbharati@kccemsr.edu.in>\n",
      "The subject of the email is: \n",
      "This is a test subject\n",
      "The body of email is:\n",
      "This is a test message\n",
      "\n",
      "Speak SEND to Send email   Speak READ to Read Inbox    Speak EXIT to exit\n",
      "Speak Now:\n",
      "Sorry could not recognize what you said\n",
      "Invalid choice.\n",
      "Speak SEND to Send email   Speak READ to Read Inbox    Speak EXIT to exit\n",
      "Speak Now:\n",
      "You have choosen to exit,Bye bye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ritu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\Ritu\\AppData\\Local\\Temp/ipykernel_10304/3959681233.py\", line 101, in SignLanguageDetection\n",
      "    detections = detect_fn(input_tensor)\n",
      "  File \"C:\\Users\\Ritu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 885, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"C:\\Users\\Ritu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 917, in _call\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"C:\\Users\\Ritu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3039, in __call__\n",
      "    return graph_function._call_flat(\n",
      "  File \"C:\\Users\\Ritu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1963, in _call_flat\n",
      "    return self._build_call_outputs(self._inference_function.call(\n",
      "  File \"C:\\Users\\Ritu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 591, in call\n",
      "    outputs = execute.execute(\n",
      "  File \"C:\\Users\\Ritu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 59, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "########################TKINTER############################\n",
    "from tkinter import *\n",
    "from tkinter import messagebox\n",
    "import tkinter as tk\n",
    "\n",
    "window = Tk()\n",
    "window.geometry(\"744x600\")\n",
    "window.title(\"SelfAssistance for Disable\")\n",
    "\n",
    "\n",
    "# This was created just for testing for actual demo run the above 2 cells\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#lOOGO IMAGE\n",
    "logoImage = PhotoImage(file=r\"D:\\python\\logo.png\")\n",
    "logoImage=logoImage.subsample(10,10)\n",
    "\n",
    "#TITLE LABEL\n",
    "Title1 = Label(window, text=\"      SelfAssistance for Disable\", width=700, height=100,borderwidth=0, image=logoImage,anchor=NW, compound=LEFT,\n",
    "               fg=\"#ef7d4c\", relief=\"solid\", font=(\"Open Sans\", 20, \"bold\"))\n",
    "Title1.place(x=20, y=12)\n",
    "\n",
    "#VOICEMAIL IMAGE\n",
    "voiceMailImage = PhotoImage(file=r\"D:\\python\\voicemail.png\").subsample(1,2)\n",
    "\n",
    "#VOICEMAIL BUTTON\n",
    "VoiceMailButton = Button(window, text=\"VoiceMail\", height=350, width=300, fg=\"white\",bg='#ef7d4c',borderwidth=0,font=(\"Open Sans\", 20, \"bold\"), image=voiceMailImage,\n",
    "                         compound=TOP,command=voicemail)  # VoiceMailButton\n",
    "VoiceMailButton.place(x=400, y=120)\n",
    "\n",
    "#SIGNLANGUAGE IMAGE\n",
    "SignLanguageImage = PhotoImage(file=r\"D:\\python\\signlanguage.png\").subsample(1,2)\n",
    "\n",
    "#SIGNLANGUAGE BUTTON\n",
    "SignLanguageButton = Button(window, text=\"SignLanguage Detection\", width=300, height=350, fg=\"white\",borderwidth=0,bg='#ef7d4c',font=(\"Open Sans\", 18, \"bold\"),image=SignLanguageImage, compound=TOP,command=SignLanguageDetection)  # command=SignLanguageDetection\n",
    "SignLanguageButton.pack(pady=20)\n",
    "SignLanguageButton.place(x=40, y=120)\n",
    "\n",
    "#EXIT BUTTON\n",
    "ExitButton = Button(window, text=\"Exit\", width=50, fg=\"white\",bg='#ef7d4c',borderwidth=0, font=(\"Open Sans\", 15, \"bold\"),command=exit)\n",
    "ExitButton.pack(pady=30)\n",
    "ExitButton.place(x=70, y=520)\n",
    "\n",
    "window.mainloop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66e3170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beee25f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
